<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T22:20:20+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "bg"
}
-->
[![Модели с отворен код](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.bg.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Фина настройка на вашия LLM

Използването на големи езикови модели за изграждане на приложения за генеративен AI идва с нови предизвикателства. Основен проблем е осигуряването на качеството на отговорите (точност и релевантност) в съдържанието, генерирано от модела за дадена потребителска заявка. В предишни уроци обсъдихме техники като инженеринг на подканите и генериране, обогатено с извличане, които се опитват да решат проблема чрез _модифициране на входа на подканата_ към съществуващия модел.

В днешния урок ще обсъдим трета техника, **фина настройка**, която се опитва да се справи с предизвикателството чрез _повторно обучение на самия модел_ с допълнителни данни. Нека се потопим в детайлите.

## Цели на обучението

Този урок представя концепцията за фина настройка на предварително обучени езикови модели, разглежда ползите и предизвикателствата на този подход и предоставя насоки кога и как да използвате фината настройка, за да подобрите производителността на вашите генеративни AI модели.

До края на този урок трябва да можете да отговорите на следните въпроси:

- Какво представлява фината настройка на езиковите модели?
- Кога и защо е полезна фината настройка?
- Как мога да направя фина настройка на предварително обучен модел?
- Какви са ограниченията на фината настройка?

Готови ли сте? Да започваме.

## Илюстрирано ръководство

Искате ли да получите обща представа за това, което ще разгледаме, преди да се потопим? Разгледайте това илюстрирано ръководство, което описва учебното пътуване за този урок - от изучаването на основните концепции и мотивацията за фина настройка до разбирането на процеса и най-добрите практики за изпълнение на задачата за фина настройка. Това е завладяваща тема за изследване, така че не забравяйте да проверите страницата [Ресурси](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) за допълнителни връзки, които да подкрепят вашето самостоятелно обучение!

![Илюстрирано ръководство за фина настройка на езикови модели](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.bg.png)

## Какво представлява фината настройка на езикови модели?

По дефиниция големите езикови модели са _предварително обучени_ върху големи количества текст, събрани от разнообразни източници, включително интернет. Както научихме в предишни уроци, ни трябват техники като _инженеринг на подканите_ и _генериране, обогатено с извличане_, за да подобрим качеството на отговорите на модела на въпросите на потребителя ("подкани").

Популярна техника за инженеринг на подканите включва даване на модела повече насоки за това какво се очаква в отговора, като се предоставят _инструкции_ (експлицитни насоки) или _няколко примера_ (имплицитни насоки). Това се нарича _обучение с малко примери_, но има два ограничения:

- Ограниченията на токените в модела могат да ограничат броя на примерите, които можете да предоставите, и да намалят ефективността.
- Разходите за токени могат да направят скъпо добавянето на примери към всяка подкана и да ограничат гъвкавостта.

Фината настройка е често срещана практика в системите за машинно обучение, при която вземаме предварително обучен модел и го обучаваме отново с нови данни, за да подобрим неговата производителност за конкретна задача. В контекста на езиковите модели можем да направим фина настройка на предварително обучен модел _с подбрана група примери за дадена задача или приложна област_, за да създадем **персонализиран модел**, който може да бъде по-точен и релевантен за тази конкретна задача или област. Допълнителна полза от фината настройка е, че може да намали броя на необходимите примери за обучение с малко примери - намалявайки използването на токени и свързаните разходи.

## Кога и защо трябва да правим фина настройка на модели?

В _този_ контекст, когато говорим за фина настройка, имаме предвид **супервизирана** фина настройка, при която повторното обучение се извършва чрез **добавяне на нови данни**, които не са били част от оригиналния набор от данни за обучение. Това е различно от подхода за несупервизирана фина настройка, при който моделът се обучава отново върху оригиналните данни, но с различни хиперпараметри.

Основното, което трябва да запомните, е, че фината настройка е напреднала техника, която изисква определено ниво на експертиза, за да се постигнат желаните резултати. Ако не се направи правилно, тя може да не предостави очакваните подобрения и дори да влоши производителността на модела за вашата целева област.

Затова, преди да научите "как" да направите фина настройка на езикови модели, трябва да знаете "защо" трябва да изберете този подход и "кога" да започнете процеса на фина настройка. Започнете, като си зададете следните въпроси:

- **Цел на използване**: Каква е вашата _цел на използване_ за фина настройка? Кой аспект на текущия предварително обучен модел искате да подобрите?
- **Алтернативи**: Опитали ли сте _други техники_, за да постигнете желаните резултати? Използвайте ги, за да създадете базова линия за сравнение.
  - Инженеринг на подканите: Опитайте техники като подканване с малко примери, включващи примери за релевантни отговори. Оценете качеството на отговорите.
  - Генериране, обогатено с извличане: Опитайте да обогатите подканите с резултати от търсене във вашите данни. Оценете качеството на отговорите.
- **Разходи**: Идентифицирали ли сте разходите за фина настройка?
  - Възможност за настройка - наличен ли е предварително обучен модел за фина настройка?
  - Усилия - за подготовка на данни за обучение, оценка и усъвършенстване на модела.
  - Изчислителни ресурси - за изпълнение на задачи за фина настройка и внедряване на модела с фина настройка.
  - Данни - достъп до достатъчно качествени примери за въздействие на фината настройка.
- **Ползи**: Потвърдили ли сте ползите от фината настройка?
  - Качество - дали моделът с фина настройка превъзхожда базовия модел?
  - Разходи - намалява ли използването на токени чрез опростяване на подканите?
  - Разширяемост - може ли базовият модел да бъде адаптиран за нови области?

Отговаряйки на тези въпроси, трябва да можете да решите дали фината настройка е правилният подход за вашата цел на използване. Идеално, подходът е валиден само ако ползите надвишават разходите. След като решите да продължите, е време да помислите _как_ можете да направите фина настройка на предварително обучен модел.

Искате ли повече информация за процеса на вземане на решения? Гледайте [Да правим ли фина настройка или не](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Как можем да направим фина настройка на предварително обучен модел?

За да направите фина настройка на предварително обучен модел, трябва да имате:

- предварително обучен модел за фина настройка
- набор от данни за използване при фината настройка
- среда за обучение за изпълнение на задачата за фина настройка
- среда за хостинг за внедряване на модела с фина настройка

## Фина настройка в действие

Следните ресурси предоставят стъпка по стъпка уроци, които ще ви преведат през реален пример, използвайки избран модел с подбран набор от данни. За да преминете през тези уроци, трябва да имате акаунт при конкретния доставчик, както и достъп до съответния модел и набори от данни.

| Доставчик    | Урок                                                                                                                                     | Описание                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ---------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Как да направим фина настройка на чат модели](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) | Научете как да направите фина настройка на `gpt-35-turbo` за конкретна област ("асистент за рецепти"), като подготвите данни за обучение, изпълните задачата за фина настройка и използвате модела с фина настройка за извеждане на резултати.                                                                                                                                                                                  |
| Azure OpenAI | [Урок за фина настройка на GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Научете как да направите фина настройка на модел `gpt-35-turbo-0613` **в Azure**, като предприемете стъпки за създаване и качване на данни за обучение, изпълнение на задачата за фина настройка. Внедрете и използвайте новия модел.                                                                                                                                                                                             |
| Hugging Face | [Фина настройка на LLMs с Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)       | Тази публикация в блог ви превежда през процеса на фина настройка на _отворен LLM_ (например `CodeLlama 7B`) с помощта на библиотеката [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) и [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) с отворени [набори от данни](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) на Hugging Face. |
|              |                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 🤗 AutoTrain | [Фина настройка на LLMs с AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                 | AutoTrain (или AutoTrain Advanced) е библиотека на Python, разработена от Hugging Face, която позволява фина настройка за много различни задачи, включително фина настройка на LLM. AutoTrain е решение без код и фината настройка може да се извърши във вашия собствен облак, на Hugging Face Spaces или локално. Тя поддържа както уеб-базирано GUI, така и CLI, както и обучение чрез yaml конфигурационни файлове.                     |
|              |                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Задача

Изберете един от горепосочените уроци и го преминете. _Може да репликираме версия на тези уроци в Jupyter Notebooks в този репо за справка. Моля, използвайте оригиналните източници директно, за да получите най-новите версии_.

## Отлична работа! Продължете да учите.

След като завършите този урок, разгледайте нашата [колекция за обучение по генеративен AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да продължите да развивате знанията си за генеративния AI!

Поздравления!! Завършихте последния урок от серията v2 за този курс! Не спирайте да учите и да създавате. \*\*Разгледайте страницата [РЕСУРСИ](RESOURCES.md?WT.mc_id=academic-105485-koreyst) за списък с допълнителни предложения само за тази тема.

Нашата серия от уроци v1 също е актуализирана с повече задачи и концепции. Затова отделете минута, за да освежите знанията си - и моля, [споделете вашите въпроси и обратна връзка](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), за да ни помогнете да подобрим тези уроци за общността.

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.