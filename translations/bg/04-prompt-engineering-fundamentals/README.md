<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0135e6c271f3ece8699050d4debbce88",
  "translation_date": "2025-10-17T22:21:50+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "bg"
}
-->
# Основи на инженерството на подканите

[![Основи на инженерството на подканите](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.bg.png)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Въведение
Този модул обхваща основни концепции и техники за създаване на ефективни подканящи текстове (prompts) за генеративни AI модели. Начинът, по който формулирате подканата си към LLM, също има значение. Внимателно създадената подкана може да доведе до по-качествен отговор. Но какво точно означават термини като _подкана_ и _инженерство на подканите_? И как можем да подобрим _входа на подканата_, който изпращаме към LLM? Това са въпросите, на които ще се опитаме да отговорим в тази глава и следващата.

_Генеративният AI_ е способен да създава ново съдържание (например текст, изображения, аудио, код и др.) в отговор на потребителски заявки. Това се постига чрез _Големи езикови модели_ като серията GPT ("Generative Pre-trained Transformer") на OpenAI, които са обучени да работят с естествен език и код.

Потребителите вече могат да взаимодействат с тези модели чрез познати парадигми като чат, без да се нуждаят от техническа експертиза или обучение. Моделите са _базирани на подканящи текстове_ - потребителите изпращат текстов вход (подкана) и получават отговор от AI (завършване). След това те могат "да разговарят с AI" многократно, като усъвършенстват подканата си, докато отговорът отговаря на техните очаквания.

"Подканите" вече се превръщат в основен _програмен интерфейс_ за приложенията на генеративния AI, като указват на моделите какво да правят и влияят върху качеството на върнатите отговори. "Инженерството на подканите" е бързо развиваща се област на изследване, която се фокусира върху _проектирането и оптимизацията_ на подканите, за да се осигурят последователни и качествени отговори в мащаб.

## Цели на обучението

В този урок ще научим какво представлява инженерството на подканите, защо е важно и как можем да създаваме по-ефективни подканящи текстове за даден модел и цел на приложението. Ще разберем основните концепции и най-добрите практики за инженерство на подканите - и ще научим за интерактивна среда "пясъчник" в Jupyter Notebooks, където можем да приложим тези концепции върху реални примери.

До края на този урок ще можем:

1. Да обясним какво представлява инженерството на подканите и защо е важно.
2. Да опишем компонентите на една подкана и как се използват.
3. Да научим най-добрите практики и техники за инженерство на подканите.
4. Да приложим научените техники върху реални примери, използвайки OpenAI endpoint.

## Основни термини

Инженерство на подканите: Практиката на проектиране и усъвършенстване на входни данни, за да се насочат AI моделите към генериране на желаните изходи.  
Токенизация: Процесът на преобразуване на текст в по-малки единици, наречени токени, които моделът може да разбере и обработи.  
LLM, настроени за инструкции: Големи езикови модели (LLMs), които са фино настроени със специфични инструкции за подобряване на точността и релевантността на техните отговори.

## Пясъчник за обучение

Инженерството на подканите в момента е повече изкуство, отколкото наука. Най-добрият начин да подобрим интуицията си за него е да _практикуваме повече_ и да възприемем подход на проба и грешка, който комбинира експертни познания в приложната област с препоръчани техники и оптимизации, специфични за модела.

Jupyter Notebook, който съпровожда този урок, предоставя среда "пясъчник", където можете да изпробвате наученото - докато напредвате или като част от предизвикателството с код в края. За да изпълните упражненията, ще ви трябват:

1. **Ключ за Azure OpenAI API** - крайна точка на услугата за разположен LLM.  
2. **Python Runtime** - в която може да се изпълни Notebook.  
3. **Локални променливи на средата** - _завършете стъпките [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), за да се подготвите_.  

Notebook включва _начални_ упражнения - но се насърчавате да добавите свои собствени секции с _Markdown_ (описание) и _Code_ (заявки за подканящи текстове), за да изпробвате повече примери или идеи - и да изградите интуиция за проектиране на подканящи текстове.

## Илюстрирано ръководство

Искате ли да получите обща представа за това, което обхваща този урок, преди да се потопите? Разгледайте това илюстрирано ръководство, което ви дава усещане за основните теми, които се разглеждат, и ключовите изводи, върху които да се замислите във всяка от тях. Пътната карта на урока ви води от разбирането на основните концепции и предизвикателства до тяхното решаване с подходящи техники и най-добри практики за инженерство на подканите. Обърнете внимание, че разделът "Напреднали техники" в това ръководство се отнася до съдържание, разгледано в _следващата_ глава от тази учебна програма.

![Илюстрирано ръководство за инженерство на подканите](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.bg.png)

## Нашият стартъп

Сега нека поговорим за това как _тази тема_ се отнася към нашата мисия за стартъп [да внесем иновации с AI в образованието](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Искаме да изградим AI-базирани приложения за _персонализирано обучение_ - така че нека помислим как различни потребители на нашето приложение биха могли да "проектират" подканящи текстове:

- **Администратори** могат да поискат от AI да _анализира данни за учебната програма, за да идентифицира пропуски в покритието_. AI може да обобщи резултатите или да ги визуализира с код.  
- **Преподаватели** могат да поискат от AI да _създаде план за урок за целева аудитория и тема_. AI може да изгради персонализиран план в определен формат.  
- **Ученици** могат да поискат от AI да _ги обучава по труден предмет_. AI може да насочва учениците с уроци, подсказки и примери, съобразени с тяхното ниво.  

Това е само върхът на айсберга. Разгледайте [Подкани за образование](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - библиотека с отворен код за подканящи текстове, курирана от експерти в образованието - за да получите по-широка представа за възможностите! _Опитайте да изпълните някои от тези подканящи текстове в пясъчника или използвайте OpenAI Playground, за да видите какво се случва!_

<!--
ШАБЛОН НА УРОКА:
Тази единица трябва да обхваща основна концепция #1.
Укрепете концепцията с примери и препратки.

КОНЦЕПЦИЯ #1:
Инженерство на подканите.
Определете го и обяснете защо е необходимо.
-->

## Какво е инженерство на подканите?

Започнахме този урок, като дефинирахме **Инженерство на подканите** като процес на _проектиране и оптимизация_ на текстови входове (подкани), за да се осигурят последователни и качествени отговори (завършвания) за дадена цел на приложението и модел. Можем да мислим за това като за двустепенен процес:

- _проектиране_ на първоначалната подкана за даден модел и цел  
- _усъвършенстване_ на подканата многократно, за да се подобри качеството на отговора  

Това е неизбежно процес на проба и грешка, който изисква интуиция и усилия от страна на потребителя, за да се постигнат оптимални резултати. Но защо е важно? За да отговорим на този въпрос, първо трябва да разберем три концепции:

- _Токенизация_ = как моделът "вижда" подканата  
- _Основни LLMs_ = как основният модел "обработва" подканата  
- _LLMs, настроени за инструкции_ = как моделът може да вижда "задачи"  

### Токенизация

LLM вижда подканите като _последователност от токени_, при което различни модели (или версии на модел) могат да токенизират една и съща подкана по различни начини. Тъй като LLMs са обучени върху токени (а не върху суров текст), начинът, по който подканите се токенизират, има пряко влияние върху качеството на генерирания отговор.

За да получите интуиция за това как работи токенизацията, опитайте инструменти като [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), показан по-долу. Копирайте вашата подкана - и вижте как тя се преобразува в токени, като обърнете внимание на начина, по който се обработват символите за интервали и пунктуационни знаци. Обърнете внимание, че този пример показва по-стар LLM (GPT-3) - така че ако опитате това с по-нов модел, може да получите различен резултат.

![Токенизация](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.bg.png)

### Концепция: Основни модели

След като подканата е токенизирана, основната функция на ["Основния LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (или Основния модел) е да предскаже следващия токен в тази последователност. Тъй като LLMs са обучени върху огромни текстови набори от данни, те имат добро усещане за статистическите връзки между токените и могат да направят тази прогноза с известна увереност. Обърнете внимание, че те не разбират _значението_ на думите в подканата или токена; те просто виждат модел, който могат да "завършат" със следващата си прогноза. Те могат да продължат да предсказват последователността, докато не бъдат прекъснати от потребителя или от някакво предварително установено условие.

Искате ли да видите как работи завършването, базирано на подканите? Въведете горната подкана в [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) на Azure OpenAI Studio с настройките по подразбиране. Системата е конфигурирана да третира подканите като заявки за информация - така че трябва да видите завършване, което отговаря на този контекст.

Но какво, ако потребителят иска да види нещо конкретно, което отговаря на някакви критерии или цел на задачата? Тук влизат в игра _LLMs, настроени за инструкции_.

![Завършване на чат с Основен LLM](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.bg.png)

### Концепция: LLMs, настроени за инструкции

[LLM, настроен за инструкции](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) започва с основния модел и го фино настройва с примери или двойки вход/изход (например многократни "съобщения"), които могат да съдържат ясни инструкции - и отговорът от AI се опитва да следва тези инструкции.

Това използва техники като Усилено обучение с обратна връзка от хора (RLHF), които могат да обучат модела да _следва инструкции_ и _да се учи от обратна връзка_, така че да произвежда отговори, които са по-подходящи за практически приложения и по-релевантни за целите на потребителя.

Нека го изпробваме - върнете се към горната подкана, но сега променете _системното съобщение_, за да предоставите следната инструкция като контекст:

> _Обобщете предоставеното съдържание за ученик от втори клас. Ограничете резултата до един параграф с 3-5 точки._

Вижте как резултатът вече е настроен да отразява желаната цел и формат? Преподавателят вече може директно да използва този отговор в своите слайдове за този клас.

![Завършване на чат с LLM, настроен за инструкции](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.bg.png)

## Защо ни е нужно инженерство на подканите?

Сега, когато знаем как подканите се обработват от LLMs, нека поговорим за _защо_ ни е нужно инженерство на подканите. Отговорът се крие в това, че текущите LLMs поставят редица предизвикателства, които правят _надеждните и последователни завършвания_ по-трудни за постигане без усилия за конструиране и оптимизация на подканите. Например:

1. **Отговорите на модела са стохастични.** _Една и съща подкана_ вероятно ще произведе различни отговори с различни модели или версии на модели. И може дори да произведе различни резултати със _същия модел_ в различни моменти. _Техниките за инженерство на подканите могат да ни помогнат да минимизираме тези вариации, като предоставим по-добри рамки_.

1. **Моделите могат да създават измислени отговори.** Моделите са предварително обучени с _големи, но ограничени_ набори от данни, което означава, че им липсва знание за концепции извън този обхват на обучение. В резултат на това те могат да произведат завършвания, които са неточни, измислени или директно противоречащи на известни факти. _Техниките за инженерство на подканите помагат на потребителите да идентифицират и смекчат такива измислици, например, като поискат от AI цитати или разсъждения_.

1. **Способностите на моделите ще варират.** По-новите модели или поколения модели ще имат по-богати способности, но също така ще донесат уникални особености и компромиси в разходите и сложността. _Инженерството на подканите може да ни помогне да разработим най-добри практики и работни процеси, които абстрахират разликите и се адаптират към специфичните изисквания на модела по мащабируем и безпроблемен начин_.

Нека видим това в действие в OpenAI или Azure OpenAI Playground:

- Използвайте една и съща подкана с различни LLM разположения (например OpenAI, Azure OpenAI, Hugging Face) - забелязахте ли вариациите?  
- Използвайте една и съща подкана многократно със _същото_ LLM разположение (например Azure OpenAI Playground) - как се различаваха тези вариации?  

### Пример за измислици

В този курс използваме термина **"измислица
Едно търсене в интернет ми показа, че има измислени разкази (например телевизионни сериали или книги) за войни на Марс - но нито една от тях не се случва през 2076 година. Логиката също ни подсказва, че 2076 е _в бъдещето_ и следователно не може да бъде свързана с реално събитие.

Какво се случва, когато използваме този въпрос с различни доставчици на LLM?

> **Отговор 1**: OpenAI Playground (GPT-35)

![Отговор 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.bg.png)

> **Отговор 2**: Azure OpenAI Playground (GPT-35)

![Отговор 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.bg.png)

> **Отговор 3**: Hugging Face Chat Playground (LLama-2)

![Отговор 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.bg.png)

Както се очакваше, всяка от моделите (или версията на модела) генерира леко различни отговори благодарение на стохастичното поведение и вариациите в способностите на модела. Например, един модел се насочва към аудитория от осми клас, докато друг предполага, че потребителят е ученик в гимназия. Но и трите модела генерираха отговори, които биха могли да убедят неинформиран потребител, че събитието е реално.

Техники за създаване на въпроси като _метапромптинг_ и _конфигурация на температурата_ могат да намалят измислиците на модела до известна степен. Нови архитектури за създаване на въпроси също интегрират нови инструменти и техники безпроблемно в потока на въпросите, за да смекчат или намалят някои от тези ефекти.

## Казус: GitHub Copilot

Нека завършим този раздел, като разгледаме как създаването на въпроси се използва в реални решения, като разгледаме един казус: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot е вашият "AI партньор програмист" - той преобразува текстови въпроси в завършвания на код и е интегриран във вашата среда за разработка (например Visual Studio Code) за безпроблемно потребителско изживяване. Както е документирано в поредица от блогове по-долу, най-ранната версия е базирана на модела OpenAI Codex - като инженерите бързо осъзнават необходимостта от фина настройка на модела и разработване на по-добри техники за създаване на въпроси, за да подобрят качеството на кода. През юли те [представиха подобрен AI модел, който надхвърля Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) за още по-бързи предложения.

Прочетете публикациите в ред, за да проследите тяхното пътешествие на учене.

- **Май 2023** | [GitHub Copilot става по-добър в разбирането на вашия код](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Май 2023** | [Вътре в GitHub: Работа с LLMs зад GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Юни 2023** | [Как да пишем по-добри въпроси за GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Юли 2023** | [GitHub Copilot надхвърля Codex с подобрен AI модел](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Юли 2023** | [Ръководство за разработчици за създаване на въпроси и LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Септември 2023** | [Как да изградим корпоративно приложение с LLM: Уроци от GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Можете също така да разгледате техния [инженерен блог](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) за повече публикации като [тази](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), която показва как тези модели и техники се _прилагат_ за задвижване на реални приложения.

---

## Конструкция на въпроси

Вече видяхме защо създаването на въпроси е важно - сега нека разберем как се _конструират_ въпросите, за да можем да оценим различни техники за по-ефективен дизайн на въпроси.

### Основен въпрос

Нека започнем с основния въпрос: текстов вход, изпратен към модела без допълнителен контекст. Ето пример - когато изпратим първите няколко думи от националния химн на САЩ към [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) на OpenAI, той незабавно _допълва_ отговора с следващите няколко реда, илюстрирайки основното предсказателно поведение.

| Въпрос (Вход)     | Допълнение (Изход)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Изглежда, че започвате текста на "The Star-Spangled Banner", националния химн на Съединените щати. Пълният текст е ...                     |

### Сложен въпрос

Сега нека добавим контекст и инструкции към основния въпрос. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) ни позволява да конструираме сложен въпрос като колекция от _съобщения_ с:

- Вход/изход двойки, отразяващи _потребителски_ вход и _асистентски_ отговор.
- Системно съобщение, което задава контекста за поведението или личността на асистента.

Заявката вече е в следната форма, където _токенизацията_ ефективно улавя съответната информация от контекста и разговора. Сега промяната на системния контекст може да бъде толкова въздействаща върху качеството на допълненията, колкото и предоставените потребителски входове.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Инструкционен въпрос

В горните примери потребителският въпрос беше прост текстов запитване, което може да се интерпретира като искане за информация. С _инструкционни_ въпроси можем да използваме този текст, за да уточним задача в повече детайли, предоставяйки по-добри насоки на AI. Ето пример:

| Въпрос (Вход)                                                                                                                                                                                                                         | Допълнение (Изход)                                                                                                        | Тип инструкция     |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :----------------- |
| Напишете описание на Гражданската война                                                                                                                                                                                                   | _върнат е прост параграф_                                                                                              | Прост              |
| Напишете описание на Гражданската война. Посочете ключови дати и събития и опишете тяхното значение                                                                                                                                     | _върнат е параграф, последван от списък с ключови дати на събития с описания_                                             | Сложен             |
| Напишете описание на Гражданската война в 1 параграф. Посочете 3 ключови дати и тяхното значение. Посочете още 3 ключови исторически фигури и техните приноси. Върнете изхода като JSON файл | _върнат е по-обширен текст в текстово поле, форматиран като JSON, който можете да копирате и валидирате при нужда_ | Сложен. Форматиран. |

## Основно съдържание

В горните примери въпросът все още беше доста отворен, позволявайки на LLM да реши коя част от предварително обучената му база данни е релевантна. С дизайна на въпроси с _основно съдържание_, входният текст се разделя на две части:

- инструкция (действие)
- релевантно съдържание (което влияе на действието)

Ето пример, където инструкцията е "обобщете това в 2 изречения".

| Въпрос (Вход)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Допълнение (Изход)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е известен на древните цивилизации още преди записаната история. Той е наречен на римския бог Юпитер.[19] Когато се наблюдава от Земята, Юпитер може да бъде достатъчно ярък, за да хвърля видими сенки,[20] и средно е третият най-ярък естествен обект в нощното небе след Луната и Венера. <br/> **Обобщете това в 2 кратки изречения** | Юпитер, петата планета от Слънцето, е най-голямата в Слънчевата система и е известен като един от най-ярките обекти в нощното небе. Наречен на римския бог Юпитер, той е газов гигант с маса, два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система, взети заедно. |

Сегментът с основно съдържание може да се използва по различни начини за по-ефективни инструкции:

- **Примери** - вместо да казвате на модела какво да прави с явна инструкция, предоставете му примери за това какво да прави и го оставете да извлече модела.
- **Подсказки** - следвайте инструкцията с "подсказка", която насочва допълнението, водейки модела към по-релевантни отговори.
- **Шаблони** - това са повторяеми 'рецепти' за въпроси с плейсхолдъри (променливи), които могат да бъдат персонализирани с данни за специфични случаи.

Нека разгледаме тези в действие.

### Използване на примери

Това е подход, при който използвате основното съдържание, за да "подадете на модела" няколко примера за желания изход за дадена инструкция и го оставяте да извлече модела за желания изход. В зависимост от броя на предоставените примери, можем да имаме въпроси без примери, с един пример, с няколко примера и т.н.

Въпросът сега се състои от три компонента:

- Описание на задачата
- Няколко примера за желания изход
- Началото на нов пример (който става имплицитно описание на задачата)

| Тип на учене | Въпрос (Вход)                                                                                                                                        | Допълнение (Изход)         |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Без примери  | "Слънцето грее". Преведете на испански                                                                                                               | "El Sol está brillando".    |
| Един пример  | "Слънцето грее" => ""El Sol está brillando". <br> "Денят е студен и ветровит" =>                                                                      | "Es un día frío y ventoso". |
| Няколко примера | Играчът пробяга базите => Бейзбол <br/> Играчът удари ас => Тенис <br/> Играчът удари шест => Крикет <br/> Играчът направи забивка =>              | Баскетбол                  |
|               |                                                                                                                                                       |                             |

Забележете как трябваше да предоставим явна инструкция ("Преведете на испански") при въпрос без примери, но тя се извежда в примера с един пример. Примерът с няколко примера показва как добавянето на повече примери позволява на моделите да правят по-точни изводи без допълнителни инструкции.

### Подсказки във въпроса

Друг метод за използване на основно съдържание е предоставянето на _подсказки_, а не примери. В този случай даваме на модела насока в правилната посока, като _започваме_ с откъс, който отразява желания формат на отговора. Моделът след това "взема подсказката", за да продължи в същия стил.

| Брой подсказки | Въпрос (Вход)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Допълнение (Изход)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но два и половина пъти по-голяма от тази на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с невъоръжено око в нощното небе, и е известен на древните цивилизации още преди записаната история. <br/>**Обобщете това**                                       | Юпитер е най-голямата планета в нашата Слънчева система и петата от Слънцето. Той е газов гигант с маса, равна на една хилядна от тази на Слънцето, но по-тежък от всички останали планети, взети заедно. Древните цивилизации са знаели за Юпитер отдавна, и той е лесно видим в нощното небе. |
| 1              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, която е една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с просто око в нощното небе, и е познат на древните цивилизации още преди записаната история. <br/>**Обобщение** <br/> Научихме, че Юпитер | е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, която е една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети, взети заедно. Лесно се вижда с просто око и е познат от древни времена.                        |
| 2              | Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. Той е газов гигант с маса, която е една хилядна от тази на Слънцето, но два и половина пъти по-голяма от масата на всички останали планети в Слънчевата система, взети заедно. Юпитер е един от най-ярките обекти, видими с просто око в нощното небе, и е познат на древните цивилизации още преди записаната история. <br/>**Обобщение** <br/> Топ 3 факта, които научихме:         | 1. Юпитер е петата планета от Слънцето и най-голямата в Слънчевата система. <br/> 2. Той е газов гигант с маса, която е една хилядна от тази на Слънцето...<br/> 3. Юпитер е видим с просто око още от древни времена ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Шаблони за подканване

Шаблон за подканване е _предварително дефинирана рецепта за подканване_, която може да се съхранява и използва повторно при необходимост, за да се постигне по-голяма последователност в потребителското изживяване в мащаб. В най-простата си форма, това е просто колекция от примери за подканване като [този от OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), който предоставя както интерактивни компоненти за подканване (съобщения от потребителя и системата), така и формат за заявка чрез API - за поддръжка на повторна употреба.

В по-сложната си форма, като [този пример от LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), той съдържа _заместители_, които могат да бъдат заменени с данни от различни източници (вход от потребителя, контекст на системата, външни източници на данни и т.н.), за да се генерира подканване динамично. Това ни позволява да създадем библиотека от повторно използваеми подканвания, които могат да се използват за постигане на последователно потребителско изживяване **програмно** в мащаб.

Накрая, истинската стойност на шаблоните се крие в способността да се създават и публикуват _библиотеки с подканвания_ за вертикални приложни домейни - където шаблонът за подканване вече е _оптимизиран_, за да отразява контекста на конкретното приложение или примери, които правят отговорите по-релевантни и точни за целевата аудитория. Репозиторият [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) е чудесен пример за този подход, като събира библиотека от подканвания за образователния домейн с акцент върху ключови цели като планиране на уроци, дизайн на учебни програми, обучение на ученици и др.

## Поддържащо съдържание

Ако разглеждаме създаването на подканвания като съставяне на инструкция (задача) и цел (основно съдържание), тогава _вторичното съдържание_ е като допълнителен контекст, който предоставяме, за да **влияе на резултата по някакъв начин**. Това може да бъдат параметри за настройка, инструкции за форматиране, таксономии на теми и т.н., които могат да помогнат на модела да _адаптира_ отговора си, за да отговаря на желаните цели или очаквания на потребителя.

Например: Като се има предвид каталог на курсове с обширни метаданни (име, описание, ниво, мета тагове, инструктор и т.н.) за всички налични курсове в учебната програма:

- можем да дефинираме инструкция за "обобщаване на каталога на курсовете за есента на 2023 г."
- можем да използваме основното съдържание, за да предоставим няколко примера за желания резултат
- можем да използваме вторичното съдържание, за да идентифицираме топ 5 "тагове" от интерес.

Сега моделът може да предостави обобщение във формата, показан от няколко примера - но ако резултатът има множество тагове, той може да приоритизира 5-те тагове, идентифицирани във вторичното съдържание.

---

<!--
ШАБЛОН ЗА УРОК:
Тази единица трябва да обхваща основна концепция #1.
Укрепете концепцията с примери и препратки.

КОНЦЕПЦИЯ #3:
Техники за инженеринг на подканвания.
Какви са основните техники за инженеринг на подканвания?
Илюстрирайте с някои упражнения.
-->

## Най-добри практики за подканване

Сега, когато знаем как подканванията могат да бъдат _създадени_, можем да започнем да мислим как да ги _проектираме_, за да отразяват най-добрите практики. Можем да мислим за това в две части - да имаме правилното _мислене_ и да прилагаме правилните _техники_.

### Мислене за инженеринг на подканвания

Инженерингът на подканвания е процес на проби и грешки, затова имайте предвид три основни насоки:

1. **Разбирането на домейна е важно.** Точността и релевантността на отговора са функция на _домейна_, в който работи приложението или потребителят. Използвайте интуицията и експертния си опит в домейна, за да **персонализирате техниките** допълнително. Например, дефинирайте _домейн-специфични личности_ в системните си подканвания или използвайте _домейн-специфични шаблони_ в потребителските си подканвания. Осигурете вторично съдържание, което отразява домейн-специфични контексти, или използвайте _домейн-специфични подсказки и примери_, за да насочите модела към познати модели на употреба.

2. **Разбирането на модела е важно.** Знаем, че моделите са стохастични по природа. Но имплементациите на моделите могат също да варират по отношение на набора от данни, който използват за обучение (предварително обучени знания), възможностите, които предоставят (например чрез API или SDK), и типа съдържание, за което са оптимизирани (например код срещу изображения срещу текст). Разберете силните и слабите страни на модела, който използвате, и използвайте тези знания, за да _приоритизирате задачи_ или да изградите _персонализирани шаблони_, които са оптимизирани за възможностите на модела.

3. **Итерация и валидиране са важни.** Моделите се развиват бързо, както и техниките за инженеринг на подканвания. Като експерт в домейна, може да имате друг контекст или критерии за _вашето_ специфично приложение, които може да не се прилагат за по-широката общност. Използвайте инструменти и техники за инженеринг на подканвания, за да "започнете" създаването на подканвания, след това итерирайте и валидирайте резултатите, използвайки собствената си интуиция и експертен опит в домейна. Запишете своите прозрения и създайте **база знания** (например библиотеки с подканвания), която може да се използва като нова основа от други за по-бързи итерации в бъдеще.

## Най-добри практики

Сега нека разгледаме общите най-добри практики, препоръчани от практикуващите [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) и [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Какво                              | Защо                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Оценявайте най-новите модели.       | Новите поколения модели вероятно имат подобрени функции и качество - но може също така да доведат до по-високи разходи. Оценявайте ги за въздействие, след това вземете решения за миграция.                                                                                |
| Разделяйте инструкции и контекст   | Проверете дали вашият модел/доставчик дефинира _разделители_, за да разграничи инструкциите, основното и вторичното съдържание по-ясно. Това може да помогне на моделите да присвояват тежести по-точно на токените.                                                         |
| Бъдете конкретни и ясни             | Дайте повече подробности за желания контекст, резултат, дължина, формат, стил и т.н. Това ще подобри както качеството, така и последователността на отговорите. Запишете рецепти в повторно използваеми шаблони.                                                          |
| Бъдете описателни, използвайте примери      | Моделите може да реагират по-добре на подхода "покажи и разкажи". Започнете с подхода `zero-shot`, където му давате инструкция (но без примери), след това опитайте `few-shot` като усъвършенстване, предоставяйки няколко примера за желания резултат. Използвайте аналогии. |
| Използвайте подсказки за започване на отговори | Насочете го към желания резултат, като му дадете някои водещи думи или фрази, които може да използва като начало за отговора.                                                                                                               |
| Повторете                       | Понякога може да се наложи да повторите инструкциите си към модела. Дайте инструкции преди и след основното съдържание, използвайте инструкция и подсказка и т.н. Итерация и валидиране, за да видите какво работи.                                                         |
| Редът има значение                     | Редът, в който представяте информацията на модела, може да повлияе на резултата, дори в учебните примери, благодарение на пристрастие към последователността. Опитайте различни опции, за да видите какво работи най-добре.                                                               |
| Дайте на модела "изход"           | Дайте на модела _резервен_ отговор, който може да предостави, ако не може да изпълни задачата по някаква причина. Това може да намали шансовете моделите да генерират неверни или измислени отговори.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Както при всяка най-добра практика, помнете, че _резултатите могат да варират_ в зависимост от модела, задачата и домейна. Използвайте тези като отправна точка и итерирайте, за да намерите това, което работи най-добре за вас. Постоянно преоценявайте процеса си за инженеринг на подканвания, когато се появяват нови модели и инструменти, с фокус върху мащабируемостта на процеса и качеството на отговорите.

<!--
ШАБЛОН ЗА УРОК:
Тази единица трябва да предостави предизвикателство с код, ако е приложимо

ПРЕДИЗВИКАТЕЛСТВО:
Линк към Jupyter Notebook с инструкции само в коментарите на кода (секциите с код са празни).

РЕШЕНИЕ:
Линк към копие на този Notebook с попълнени и изпълнени подканвания, показващ как може да изглежда един пример.
-->

## Задача

Поздравления! Стигнахте до края на урока! Време е да приложите някои от тези концепции и техники на практика с реални примери!

За нашата задача ще използваме Jupyter Notebook с упражнения, които можете да изпълните интерактивно. Можете също така да разширите Notebook с ваши собствени клетки за Markdown и код, за да изследвате идеи и техники самостоятелно.

### За да започнете, направете fork на репото, след това

- (Препоръчително) Стартирайте GitHub Codespaces
- (Алтернативно) Клонирайте репото на вашето локално устройство и го използвайте с Docker Desktop
- (Алтернативно) Отворете Notebook с предпочитаната от вас среда за изпълнение на Notebook.

### След това конфигурирайте вашите променливи на средата

- Копирайте файла `.env.copy` от корена на репото в `.env` и попълнете стойностите за `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` и `AZURE_OPENAI_DEPLOYMENT`. Върнете се към [секцията Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), за да научите как.

### След това отворете Jupyter Notebook

- Изберете ядрото за изпълнение. Ако използвате опции 1 или 2, просто изберете стандартното Python 3.10.x ядро, предоставено от контейнера за разработка.

Вече сте готови да изпълните упражненията. Имайте предвид, че тук няма _правилни и грешни_ отговори - просто изследвате опции чрез проби и грешки и изграждате интуиция за това, което работи за даден модел и приложен домейн.

_Поради тази причина няма сегменти с решения на кода в този урок. Вместо това Notebook ще има клетки с Markdown, озаглавени "Моето решение:", които показват един примерен резултат за справка._

 <!--
ШАБЛОН ЗА УРОК:
Завършете секцията с обобщение и ресурси за самостоятелно обучение.
-->

## Проверка на знанията

Кое от следните е добро подканване, следващо някои разумни най-добри практики?

1. Покажи ми изображение на червена кола
2. Покажи ми изображение на червена кола от марка Volvo и модел XC90, паркирана до скала с залязващо слънце
3. Покажи ми изображение на червена кола от марка Volvo и модел XC90

О: 2, това е най-доброто подканване, тъй като предоставя подробности за "какво" и влиза в конкретика (не просто някаква кола, а конкретна марка и модел) и също така описва общата обстановка. 3 е следващото най-добро, тъй като също съдържа много описание.

## 🚀 Предизвикателство

Опитайте да използвате техниката "подсказка" с подканването: Завършете изречението "Покажи ми изображение на червена кола от марка Volvo и ". Какво ще отговори моделът и как бихте го подобрили?

## Чудесна работа! Продължете да учите

Искате ли да научите повече за различните концепции на инженеринг на подканвания? Отидете на [страницата за продължаващо обучение](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да намерите други страхотни ресурси по тази тема.

Преминете към Урок 5, където ще разгледаме [усъвършенствани техники

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.