<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a2a83aac52158c23161046cbd13faa2b",
  "translation_date": "2025-10-17T22:23:27+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "bg"
}
-->
[![Модели с отворен код](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.bg.png)](https://youtu.be/CuICgfuHFSg?si=x8SpFRUsIxM9dohN)

## Въведение

Светът на LLMs с отворен код е вълнуващ и постоянно се развива. Този урок има за цел да предостави задълбочен поглед върху моделите с отворен код. Ако търсите информация за това как се сравняват собствените модели с моделите с отворен код, посетете урока ["Изследване и сравнение на различни LLMs"](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst). Този урок също така ще разгледа темата за фина настройка, но по-подробно обяснение може да се намери в урока ["Фина настройка на LLMs"](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst).

## Цели на обучението

- Придобиване на разбиране за модели с отворен код
- Разбиране на предимствата от работата с модели с отворен код
- Изследване на наличните модели с отворен код в Hugging Face и Azure AI Studio

## Какво представляват моделите с отворен код?

Софтуерът с отворен код играе ключова роля в развитието на технологиите в различни области. Open Source Initiative (OSI) е дефинирала [10 критерия за софтуер](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst), за да бъде класифициран като отворен код. Изходният код трябва да бъде споделен открито под лиценз, одобрен от OSI.

Докато разработването на LLMs има сходни елементи с разработването на софтуер, процесът не е напълно идентичен. Това предизвика много дискусии в общността относно дефиницията на отворен код в контекста на LLMs. За да бъде моделът съобразен с традиционната дефиниция на отворен код, следната информация трябва да бъде публично достъпна:

- Наборите от данни, използвани за обучение на модела.
- Пълните тегла на модела като част от обучението.
- Кодът за оценка.
- Кодът за фина настройка.
- Пълните тегла на модела и метриките за обучение.

В момента има само няколко модела, които отговарят на тези критерии. [Моделът OLMo, създаден от Allen Institute for Artificial Intelligence (AllenAI)](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) е един от тях.

За целите на този урок, ще наричаме моделите "отворени модели", тъй като те може да не отговарят на горните критерии към момента на писане.

## Предимства на отворените модели

**Висока персонализация** - Тъй като отворените модели се публикуват с подробна информация за обучението, изследователите и разработчиците могат да модифицират вътрешната структура на модела. Това позволява създаването на силно специализирани модели, които са фино настроени за конкретна задача или област на изследване. Някои примери за това са генериране на код, математически операции и биология.

**Цена** - Цената на токен за използване и внедряване на тези модели е по-ниска от тази на собствените модели. При изграждането на приложения за Генеративен AI, трябва да се разгледа съотношението между производителност и цена при работа с тези модели за вашия случай на употреба.

![Цена на модела](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.bg.png)  
Източник: Artificial Analysis

**Гъвкавост** - Работата с отворени модели ви позволява да бъдете гъвкави по отношение на използването на различни модели или комбинирането им. Пример за това е [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst), където потребителят може директно да избере модела, който се използва в потребителския интерфейс:

![Избор на модел](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.bg.png)

## Изследване на различни отворени модели

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), разработен от Meta, е отворен модел, оптимизиран за приложения, базирани на чат. Това се дължи на метода му за фина настройка, който включва голямо количество диалог и обратна връзка от хора. С този метод моделът генерира повече резултати, които са съобразени с очакванията на хората, което осигурява по-добро потребителско изживяване.

Някои примери за фино настроени версии на Llama включват [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), който се специализира в японски език, и [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), който е подобрена версия на основния модел.

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) е отворен модел с акцент върху висока производителност и ефективност. Той използва подхода Mixture-of-Experts, който комбинира група от специализирани експертни модели в една система, където в зависимост от входа се избират определени модели за използване. Това прави изчисленията по-ефективни, тъй като моделите се занимават само с входовете, в които са специализирани.

Някои примери за фино настроени версии на Mistral включват [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), който е фокусиран върху медицинската област, и [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), който извършва математически изчисления.

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) е LLM, създаден от Technology Innovation Institute (**TII**). Falcon-40B е обучен с 40 милиарда параметри, което показва, че се представя по-добре от GPT-3 с по-малък бюджет за изчисления. Това се дължи на използването на алгоритъма FlashAttention и multiquery attention, които му позволяват да намали изискванията за памет по време на извеждане. С намаленото време за извеждане, Falcon-40B е подходящ за приложения за чат.

Някои примери за фино настроени версии на Falcon са [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), асистент, базиран на отворени модели, и [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), който предоставя по-висока производителност от основния модел.

## Как да изберем

Няма един отговор за избора на отворен модел. Добро начало е използването на функцията за филтриране по задача в Azure AI Studio. Това ще ви помогне да разберете какви типове задачи моделът е бил обучен да изпълнява. Hugging Face също поддържа LLM Leaderboard, който показва най-добре представящите се модели въз основа на определени метрики.

Когато искате да сравните LLMs между различните типове, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) е друг отличен ресурс:

![Качество на модела](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.bg.png)  
Източник: Artificial Analysis

Ако работите върху конкретен случай на употреба, търсенето на фино настроени версии, които са фокусирани върху същата област, може да бъде ефективно. Експериментирането с множество отворени модели, за да видите как се представят според вашите и очакванията на вашите потребители, е друга добра практика.

## Следващи стъпки

Най-добрата част от отворените модели е, че можете да започнете да работите с тях доста бързо. Разгледайте [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst), който включва специфична колекция на Hugging Face с моделите, които обсъдихме тук.

## Обучението не спира тук, продължете пътешествието

След като завършите този урок, разгледайте нашата [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да продължите да развивате знанията си за Генеративен AI!

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или погрешни интерпретации, произтичащи от използването на този превод.