<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "58953c08b8ba7073b836d4270ea0fe86",
  "translation_date": "2025-10-17T22:15:09+00:00",
  "source_file": "08-building-search-applications/README.md",
  "language_code": "bg"
}
-->
# Създаване на приложения за търсене

[![Въведение в Генеративния AI и Големите Езикови Модели](../../../translated_images/08-lesson-banner.8fff48c566dad08a1cbb9f4b4a2c16adfdd288a7bbfffdd30770b466fe08c25c.bg.png)](https://youtu.be/W0-nzXjOjr0?si=GcsqiTTvd7RKbo7V)

> > _Кликнете върху изображението по-горе, за да гледате видеото на този урок_

Големите езикови модели (LLMs) не са само за чатботове и генериране на текст. С тях е възможно да се създават и приложения за търсене, използвайки вградени представяния (Embeddings). Вградените представяния са числови репрезентации на данни, известни още като вектори, и могат да се използват за семантично търсене на данни.

В този урок ще създадете приложение за търсене за нашия образователен стартъп. Нашият стартъп е неправителствена организация, която предоставя безплатно образование на ученици в развиващите се страни. Стартъпът разполага с голям брой видеоклипове в YouTube, които учениците могат да използват, за да научат повече за AI. Стартъпът иска да създаде приложение за търсене, което да позволява на учениците да намират видеоклипове в YouTube, като въведат въпрос.

Например, ученик може да въведе „Какво представляват Jupyter Notebooks?“ или „Какво е Azure ML?“ и приложението за търсене ще върне списък с видеоклипове в YouTube, които са свързани с въпроса, а още по-добре – приложението ще върне линк към мястото във видеото, където се намира отговорът на въпроса.

## Въведение

В този урок ще разгледаме:

- Семантично срещу ключово търсене.
- Какво представляват текстовите вградени представяния.
- Създаване на индекс на текстови вградени представяния.
- Търсене в индекс на текстови вградени представяния.

## Цели на обучението

След завършване на този урок ще можете:

- Да различавате семантичното от ключовото търсене.
- Да обясните какво представляват текстовите вградени представяния.
- Да създадете приложение, използващо вградени представяния за търсене на данни.

## Защо да създадем приложение за търсене?

Създаването на приложение за търсене ще ви помогне да разберете как да използвате вградените представяния за търсене на данни. Освен това ще научите как да създадете приложение за търсене, което учениците могат да използват, за да намират информация бързо.

Урокът включва индекс на вградени представяния на транскрипциите от YouTube канала на Microsoft [AI Show](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1). AI Show е YouTube канал, който обучава за AI и машинно обучение. Индексът на вградените представяния съдържа представянията на всяка транскрипция от YouTube до октомври 2023 г. Ще използвате този индекс, за да създадете приложение за търсене за нашия стартъп. Приложението за търсене ще връща линк към мястото във видеото, където се намира отговорът на въпроса. Това е чудесен начин учениците да намират необходимата им информация бързо.

Ето пример за семантично търсене на въпроса „Може ли да се използва rstudio с azure ml?“. Вижте URL адреса на YouTube – той съдържа времеви маркер, който ви отвежда до мястото във видеото, където се намира отговорът на въпроса.

![Семантично търсене за въпроса "Може ли да се използва rstudio с Azure ML"](../../../translated_images/query-results.bb0480ebf025fac69c5179ad4d53b6627d643046838c857dc9e2b1281f1cdeb7.bg.png)

## Какво е семантично търсене?

Може би се чудите какво е семантично търсене? Семантичното търсене е техника за търсене, която използва семантиката или значението на думите в заявката, за да върне подходящи резултати.

Ето пример за семантично търсене. Да кажем, че искате да купите кола и търсите „моята мечтана кола“. Семантичното търсене разбира, че не „мечтаете“ за кола, а по-скоро търсите вашата „идеална“ кола. Семантичното търсене разбира вашето намерение и връща подходящи резултати. Алтернативата е „ключово търсене“, което буквално би търсило мечти за коли и често връща неподходящи резултати.

## Какво представляват текстовите вградени представяния?

[Текстовите вградени представяния](https://en.wikipedia.org/wiki/Word_embedding?WT.mc_id=academic-105485-koreyst) са техника за представяне на текст, използвана в [обработката на естествен език](https://en.wikipedia.org/wiki/Natural_language_processing?WT.mc_id=academic-105485-koreyst). Те са семантични числови репрезентации на текст. Вградените представяния се използват за представяне на данни по начин, който е лесен за разбиране от машините. Съществуват много модели за създаване на текстови вградени представяния, но в този урок ще се фокусираме върху генерирането на представяния с помощта на OpenAI Embedding Model.

Ето пример: представете си, че следният текст е част от транскрипция на един от епизодите в YouTube канала AI Show:

```text
Today we are going to learn about Azure Machine Learning.
```

Ще предадем текста на OpenAI Embedding API и той ще върне следното представяне, състоящо се от 1536 числа, известни като вектор. Всяко число във вектора представлява различен аспект на текста. За краткост, ето първите 10 числа във вектора.

```python
[-0.006655829958617687, 0.0026128944009542465, 0.008792596869170666, -0.02446001023054123, -0.008540431968867779, 0.022071078419685364, -0.010703742504119873, 0.003311325330287218, -0.011632772162556648, -0.02187200076878071, ...]
```

## Как се създава индексът на вградените представяния?

Индексът на вградените представяния за този урок беше създаден с поредица от Python скриптове. Ще намерите скриптовете заедно с инструкции в [README](./scripts/README.md?WT.mc_id=academic-105485-koreyst) в папката 'scripts' за този урок. Не е необходимо да изпълнявате тези скриптове, за да завършите урока, тъй като индексът на вградените представяния е предоставен за вас.

Скриптовете изпълняват следните операции:

1. Транскрипцията на всеки видеоклип в плейлиста [AI Show](https://www.youtube.com/playlist?list=PLlrxD0HtieHi0mwteKBOfEeOYf0LJU4O1) се изтегля.
2. С помощта на [OpenAI Functions](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?WT.mc_id=academic-105485-koreyst) се прави опит за извличане на името на говорителя от първите 3 минути на транскрипцията. Името на говорителя за всеки видеоклип се съхранява в индекса на вградените представяния, наречен `embedding_index_3m.json`.
3. Текстът на транскрипцията се разделя на **3-минутни текстови сегменти**. Сегментът включва около 20 думи, които се припокриват със следващия сегмент, за да се гарантира, че представянето на сегмента не е прекъснато и за да се осигури по-добър контекст за търсене.
4. Всеки текстов сегмент се предава на OpenAI Chat API, за да се обобщи текстът в 60 думи. Обобщението също се съхранява в индекса на вградените представяния `embedding_index_3m.json`.
5. Накрая текстовият сегмент се предава на OpenAI Embedding API. Embedding API връща вектор от 1536 числа, които представляват семантичното значение на сегмента. Сегментът заедно с вектора на OpenAI Embedding се съхранява в индекса на вградените представяния `embedding_index_3m.json`.

### Векторни бази данни

За опростяване на урока индексът на вградените представяния се съхранява в JSON файл, наречен `embedding_index_3m.json`, и се зарежда в Pandas DataFrame. В производствени условия обаче индексът на вградените представяния би се съхранявал във векторна база данни като [Azure Cognitive Search](https://learn.microsoft.com/training/modules/improve-search-results-vector-search?WT.mc_id=academic-105485-koreyst), [Redis](https://cookbook.openai.com/examples/vector_databases/redis/readme?WT.mc_id=academic-105485-koreyst), [Pinecone](https://cookbook.openai.com/examples/vector_databases/pinecone/readme?WT.mc_id=academic-105485-koreyst), [Weaviate](https://cookbook.openai.com/examples/vector_databases/weaviate/readme?WT.mc_id=academic-105485-koreyst) и други.

## Разбиране на косинусната сходност

Научихме за текстовите вградени представяния, следващата стъпка е да научим как да ги използваме за търсене на данни и по-специално за намиране на най-сходните представяния спрямо дадена заявка, използвайки косинусна сходност.

### Какво е косинусна сходност?

Косинусната сходност е мярка за сходство между два вектора, която често се нарича `търсене на най-близкия съсед`. За да извършите търсене с косинусна сходност, трябва да _векторизирате_ текста на _заявката_, използвайки OpenAI Embedding API. След това изчислявате _косинусната сходност_ между вектора на заявката и всеки вектор в индекса на вградените представяния. Запомнете, индексът на вградените представяния има вектор за всеки текстов сегмент от транскрипцията на YouTube. Накрая сортирате резултатите по косинусна сходност, като текстовите сегменти с най-висока косинусна сходност са най-сходни със заявката.

От математическа гледна точка, косинусната сходност измерва косинуса на ъгъла между два вектора, проектирани в многомерно пространство. Това измерване е полезно, защото ако два документа са далеч един от друг по Евклидово разстояние заради размера си, те все пак могат да имат по-малък ъгъл помежду си и следователно по-висока косинусна сходност. За повече информация относно уравненията за косинусна сходност, вижте [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity?WT.mc_id=academic-105485-koreyst).

## Създаване на първото ви приложение за търсене

Следва да научим как да създадем приложение за търсене, използвайки вградени представяния. Приложението за търсене ще позволи на учениците да търсят видеоклип, като въведат въпрос. Приложението ще върне списък с видеоклипове, които са свързани с въпроса. Освен това ще върне линк към мястото във видеото, където се намира отговорът на въпроса.

Това решение беше създадено и тествано на Windows 11, macOS и Ubuntu 22.04, използвайки Python 3.10 или по-нова версия. Можете да изтеглите Python от [python.org](https://www.python.org/downloads/?WT.mc_id=academic-105485-koreyst).

## Задача - създаване на приложение за търсене, за да помогнем на учениците

Представихме нашия стартъп в началото на този урок. Сега е време да помогнем на учениците да създадат приложение за търсене за техните оценки.

В тази задача ще създадете Azure OpenAI Services, които ще се използват за създаване на приложението за търсене. Ще създадете следните Azure OpenAI Services. Ще ви е необходим абонамент за Azure, за да завършите тази задача.

### Стартиране на Azure Cloud Shell

1. Влезте в [Azure портала](https://portal.azure.com/?WT.mc_id=academic-105485-koreyst).
2. Изберете иконата Cloud Shell в горния десен ъгъл на Azure портала.
3. Изберете **Bash** за тип на средата.

#### Създаване на ресурсна група

> За тези инструкции използваме ресурсна група с име "semantic-video-search" в East US.
> Можете да промените името на ресурсната група, но при промяна на местоположението на ресурсите,
> проверете [таблицата за наличност на модели](https://aka.ms/oai/models?WT.mc_id=academic-105485-koreyst).

```shell
az group create --name semantic-video-search --location eastus
```

#### Създаване на ресурс за Azure OpenAI Service

От Azure Cloud Shell изпълнете следната команда, за да създадете ресурс за Azure OpenAI Service.

```shell
az cognitiveservices account create --name semantic-video-openai --resource-group semantic-video-search \
    --location eastus --kind OpenAI --sku s0
```

#### Получаване на крайна точка и ключове за използване в това приложение

От Azure Cloud Shell изпълнете следните команди, за да получите крайна точка и ключове за ресурса Azure OpenAI Service.

```shell
az cognitiveservices account show --name semantic-video-openai \
   --resource-group  semantic-video-search | jq -r .properties.endpoint
az cognitiveservices account keys list --name semantic-video-openai \
   --resource-group semantic-video-search | jq -r .key1
```

#### Разгръщане на модела OpenAI Embedding

От Azure Cloud Shell изпълнете следната команда, за да разположите модела OpenAI Embedding.

```shell
az cognitiveservices account deployment create \
    --name semantic-video-openai \
    --resource-group  semantic-video-search \
    --deployment-name text-embedding-ada-002 \
    --model-name text-embedding-ada-002 \
    --model-version "2"  \
    --model-format OpenAI \
    --sku-capacity 100 --sku-name "Standard"
```

## Решение

Отворете [решението в notebook](./python/aoai-solution.ipynb?WT.mc_id=academic-105485-koreyst) в GitHub Codespaces и следвайте инструкциите в Jupyter Notebook.

Когато изпълните notebook-а, ще бъдете подканени да въведете заявка. Полето за въвеждане ще изглежда така:

![Поле за въвеждане на заявка от потребителя](../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.bg.png)

## Отлична работа! Продължете обучението си

След като завършите този урок, разгледайте нашата [колекция за обучение по Генеративен AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да продължите да развивате знанията си за Генеративния AI!

Преминете към Урок 9, където ще разгледаме как да [създадем приложения за генериране на изображения](../09-building-image-applications/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.